# Ollama Recursive

Give llama LLM models the same prompt in a loop, and store the results in a directory.

> :warning: **Saving outputs may be a destructive action**: Ensure that the selected directory to save files to is empty. You will likely need to change this each time to avoid overwritting previous outputs!
